name: International Gossip Bot (Gemini 3 Flash)

on:
  schedule:
    - cron: '30 1 * * *'  # 4:30AM EAT
    - cron: '30 5 * * *'  # 8:30AM EAT
    - cron: '30 10 * * *' # 1:30PM EAT
    - cron: '30 13 * * *' # 4:30PM EAT
    - cron: '30 17 * * *' # 8:30PM EAT
    - cron: '30 21 * * *' # 12:30AM EAT
  workflow_dispatch:
    inputs:
      manual_topic:
        description: 'Force topic: celebrity, sports, technology, politics'
        required: false
        default: ''

permissions:
  contents: write

env:
  DEFAULT_BRANCH: main
  POSTS_DIR: content/posts

jobs:
  generate-and-publish:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          ref: ${{ env.DEFAULT_BRANCH }}
          token: ${{ secrets.PERSONAL_GITHUB_TOKEN || secrets.GITHUB_TOKEN }}
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests google-genai

      - name: Generate article with Gemini
        env:
          GEMINI_WRITE_KEY: ${{ secrets.GEMINI_WRITE_KEY }}
          NEWSAPI_KEY: ${{ secrets.NEWSAPI_KEY }}
          UNSPLASH_ACCESS_KEY: ${{ secrets.UNSPLASH_ACCESS_KEY }}
          MANUAL_TOPIC: ${{ inputs.manual_topic }}
          POSTS_DIR: ${{ env.POSTS_DIR }}
        run: |
          python << 'EOF'
          import os, json, datetime, requests, re, random, time, sys
          from google import genai
          from google.genai import types

          # --- 1. CONFIGURATION ---
          today_str = datetime.datetime.utcnow().strftime("%Y-%m-%d")
          full_date_str = datetime.datetime.utcnow().strftime("%A, %B %d, %Y")
          current_hour = datetime.datetime.utcnow().hour

          # UPDATED MODEL LIST FOR 2026
          MODELS_TO_TRY = ["gemini-3-flash-preview", "gemini-2.5-flash"]

          # BANNED: Old/Repetitive Millennial Slang to avoid
          BANNED_PHRASES = [
              "sasa basi", "melting the pot", "spill the tea", "tea is hot", 
              "grab your popcorn", "listen up", "buckle up", "breaking news",
              "sherehe", "form ni gani", "udaku", "hello guys", "welcome back"
          ]

          # Topic rotation
          manual_input = os.environ.get('MANUAL_TOPIC', '').strip().lower()
          if manual_input in ['celebrity', 'sports', 'technology', 'politics']:
              topic = manual_input
          else:
              hour_mod = current_hour % 6
              topics = ['celebrity', 'sports', 'technology', 'politics', 'celebrity', 'sports']
              topic = topics[hour_mod] if hour_mod < len(topics) else 'celebrity'
          
          cat_map = {'celebrity': 'entertainment', 'sports': 'sports', 'technology': 'technology', 'politics': 'general'}
          newsapi_cat = cat_map.get(topic, 'general')
          
          print(f"üéØ Topic: {topic} | NewsAPI: {newsapi_cat}")

          # --- 2. FETCH INTERNATIONAL NEWS ---
          params = {
              'category': newsapi_cat,
              'language': 'en',
              'pageSize': 15,
              'apiKey': os.environ['NEWSAPI_KEY']
          }
          try:
              news_resp = requests.get('https://newsapi.org/v2/top-headlines', params=params, timeout=15)
              news_data = news_resp.json()
          except Exception as e:
              print(f"Error fetching news: {e}")
              sys.exit(0)
          
          if news_data.get('status') != 'ok':
              print(f"‚ùå NewsAPI Error: {news_data.get('message', 'Unknown error')}")
              sys.exit(0)

          if news_data.get('totalResults', 0) == 0:
              print("No fresh news, skipping")
              sys.exit(0)
          
          top_story = max(news_data['articles'], key=lambda x: x['publishedAt'] if x['publishedAt'] else '0000')
          title = top_story['title']
          desc = top_story.get('description') or ""
          content = top_story.get('content') or ""
          snippet = (desc + " " + content).strip()[:500]
          
          print(f"üì∞ NewsAPI Headline: {title[:80]}...")

          # --- 3. HELPERS ---
          def get_real_image(query):
              access_key = os.environ.get("UNSPLASH_ACCESS_KEY")
              fallback_image = "https://images.unsplash.com/photo-1504711434969-e33886168f5c?w=1200"
              if not access_key: return fallback_image
              url = f"https://api.unsplash.com/photos/random?query={query}&orientation=landscape&client_id={access_key}"
              try:
                  resp = requests.get(url, timeout=10)
                  if resp.status_code == 200:
                      return resp.json()['urls']['regular']
              except Exception: pass
              return fallback_image

          def dash_scrubber(text):
              return text.replace('\u2014', '-').replace('\u2013', '-')

          # --- 4. GROUNDED GENERATION ---
          client = genai.Client(api_key=os.environ.get("GEMINI_WRITE_KEY"))
          google_search_tool = types.Tool(google_search=types.GoogleSearch())

          prompt = f'''Current Date: {full_date_str}
          NEWS HEADLINE: "{title}"
          SOURCE SNIPPET: "{snippet}"

          TASK: 
          1. Use Google Search to research the latest details on this story.
          2. Write an article as a **Nairobi Gen Z Gossip Reporter** (Investigative but Street Smart).

          LANGUAGE MANDATE (STRICT):
          - WRITE IN PURE KENYAN SHENG ONLY.
          - TONE: You are NOT just a fan. You are a **REPORTER**. Use phrases that imply you dug for info (e.g., "Tumenusa hii story," "Sources wanasema," "Inspecta wetu wameconfirm").
          - DO NOT USE FORMAL ENGLISH OR STANDARD ENGLISH.
          - DO NOT USE OLD SLANG.
          - Autonomously find and use the latest trending street terms that fit this specific topic.
          - BANNED PHRASES (DO NOT USE): {", ".join(BANNED_PHRASES)}.

          STRICT OUTPUT FORMAT:
          TITLE: [Investigative/Savage Sheng Title]
          SLUG: [url-friendly-lowercase]
          EXCERPT: [Reporter-style hook in Sheng]
          CATEGORY: {topic.capitalize()}
          TAGS: [comma, separated, tags]
          IMAGE_KEYWORD: [search query]
          BODY:
          [Article text in pure Sheng. Structure it like a report: The Scoop -> The Evidence -> The Verdict.]
          '''

          full_text = ""
          success_flag = False
          
          for model_id in MODELS_TO_TRY:
              print(f"ü§ñ Attempting with {model_id}...")
              for retry in range(2):
                  try:
                      response = client.models.generate_content(
                          model=model_id,
                          contents=prompt,
                          config=types.GenerateContentConfig(
                              temperature=0.9,
                              tools=[google_search_tool]
                          )
                      )
                      full_text = dash_scrubber(response.text.strip())
                      success_flag = True
                      print(f"‚úÖ SUCCESS with {model_id}!")
                      break 
                  except Exception as e:
                      if "429" in str(e):
                          print("‚è≥ Quota hit. Waiting 35s...")
                          time.sleep(35)
                          continue
                      print(f"‚ö†Ô∏è Error with {model_id}: {e}")
                      break
              if success_flag: break

          if not success_flag: sys.exit(1)

          # --- 5. PARSE & SAVE ---
          parsed = { "TITLE": "", "SLUG": "", "EXCERPT": "", "CATEGORY": "", "TAGS": "", "IMAGE_KEYWORD": "", "BODY": "" }
          current_section = None
          for line in full_text.splitlines():
              clean = line.strip().replace("**", "")
              if clean.startswith("TITLE:"): parsed["TITLE"] = clean.replace("TITLE:", "").strip()
              elif clean.startswith("SLUG:"): parsed["SLUG"] = clean.replace("SLUG:", "").strip()
              elif clean.startswith("EXCERPT:"): parsed["EXCERPT"] = clean.replace("EXCERPT:", "").strip()
              elif clean.startswith("CATEGORY:"): parsed["CATEGORY"] = clean.replace("CATEGORY:", "").strip()
              elif clean.startswith("TAGS:"): parsed["TAGS"] = clean.replace("TAGS:", "").strip()
              elif clean.startswith("IMAGE_KEYWORD:"): parsed["IMAGE_KEYWORD"] = clean.replace("IMAGE_KEYWORD:", "").strip()
              elif clean.startswith("BODY:"):
                  current_section = "BODY"
                  continue
              elif current_section == "BODY":
                  parsed["BODY"] += line + "\n"

          image_url = get_real_image(parsed['IMAGE_KEYWORD'])
          
          final_file = f"""---
          title: "{parsed['TITLE'].replace('"', "'")}"
          slug: "{parsed['SLUG']}"
          excerpt: "{parsed['EXCERPT'].replace('"', "'")}"
          image: "{image_url}"
          category: "{parsed['CATEGORY']}"
          date: "{today_str}"
          tags: [{parsed['TAGS']}]
          ---

          {parsed['BODY'].strip()}
          """
          
          out_dir = os.path.join(os.getcwd(), os.environ.get("POSTS_DIR", "content/posts"))
          os.makedirs(out_dir, exist_ok=True)
          with open(os.path.join(out_dir, f"{parsed['SLUG']}.md"), "w", encoding="utf-8") as f:
              f.write(final_file)
          
          print(f"‚úÖ File saved: {parsed['SLUG']}.md")
          EOF

      - name: Commit and push article
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "content: fresh gossip via Gemini 3 Flash ‚òï"
          branch: ${{ env.DEFAULT_BRANCH }}
          file_pattern: ${{ env.POSTS_DIR }}/*.md