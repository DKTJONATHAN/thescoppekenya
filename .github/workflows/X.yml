name: Auto-Tweet New Gossip

on:
  push:
    paths:
      - 'content/posts/*.md'
  workflow_dispatch:

jobs:
  tweet_article:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 2 # Fetch at least 2 commits to find the diff

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install tweepy

      - name: Compose and Send Tweet
        env:
          TWITTER_CONSUMER_KEY: ${{ secrets.TWITTER_CONSUMER_KEY }}
          TWITTER_CONSUMER_SECRET: ${{ secrets.TWITTER_CONSUMER_SECRET }}
          TWITTER_ACCESS_TOKEN: ${{ secrets.TWITTER_ACCESS_TOKEN }}
          TWITTER_ACCESS_SECRET: ${{ secrets.TWITTER_ACCESS_SECRET }}
        run: |
          python << 'EOF'
          import os, sys, re, time, subprocess, tweepy

          # 1. Authenticate with X API using exact secret names
          api_key = os.environ.get('TWITTER_CONSUMER_KEY')
          api_secret = os.environ.get('TWITTER_CONSUMER_SECRET')
          access_token = os.environ.get('TWITTER_ACCESS_TOKEN')
          access_secret = os.environ.get('TWITTER_ACCESS_SECRET')

          if not all([api_key, api_secret, access_token, access_secret]):
              print("Error: Missing Twitter API credentials.")
              sys.exit(1)

          # 2. Find the brand new markdown file from the git commit
          result = subprocess.run(['git', 'diff', '--name-only', 'HEAD~1', 'HEAD'], capture_output=True, text=True)
          files = result.stdout.splitlines()
          md_files = [f for f in files if f.startswith('content/posts/') and f.endswith('.md')]

          if not md_files:
              print("No new markdown files found in this push. Skipping tweet.")
              sys.exit(0)

          latest_file = md_files[0]
          print(f"üìç Found new article: {latest_file}")

          # 3. Read the file and extract the juicy details
          with open(latest_file, 'r', encoding='utf-8') as f:
              content = f.read()

          try:
              title = re.search(r'title:\s*"(.*?)"', content).group(1)
              excerpt = re.search(r'excerpt:\s*"(.*?)"', content).group(1)
              slug = re.search(r'slug:\s*"(.*?)"', content).group(1)
          except AttributeError:
              print("Error: Could not parse frontmatter from the markdown file.")
              sys.exit(1)

          article_link = f"https://zandani.co.ke/posts/{slug}"

          # 4. The 30-Second Wait
          # This gives your website time to finish deploying so Twitter can successfully scrape the image!
          print("‚è≥ Waiting 30 seconds for the website to publish...")
          time.sleep(30)

          # 5. Connect to X (Twitter) API v2
          client = tweepy.Client(
              consumer_key=api_key,
              consumer_secret=api_secret,
              access_token=access_token,
              access_token_secret=access_secret
          )

          # 6. Format the Tweet
          # X links always take up exactly 23 characters, leaving us 257 for the text
          main_text = f"{title}\n\n{excerpt}"
          if len(main_text) > 220:
              main_text = main_text[:217] + "..."

          # By putting the link in the main tweet, X will automatically generate the image card
          tweet_content = f"{main_text}\n\nRead full article here: {article_link}"

          # 7. Post the Tweet
          print("üìù Posting tweet with link preview...")
          try:
              response = client.create_tweet(text=tweet_content)
              print(f"‚úÖ Tweet sent successfully! ID: {response.data['id']}")
          except Exception as e:
              print(f"Failed to send tweet: {e}")
              sys.exit(1)

          EOF